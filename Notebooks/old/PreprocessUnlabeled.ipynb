{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Preprocessing Training Unlabelled Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"..\\\\Scripts\")\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ImageDatastore import ImageDatastore\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(232, interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "        transforms.Pad(padding=(0, 0, 0, 0), fill=0),\n",
    "        transforms.CenterCrop((232, 232)),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Splitting the data into smaller chunks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Image",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Label",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "e6f72e12-ba24-4500-88f3-39a8176391f5",
       "rows": [
        [
         "0",
         "Image",
         "Label"
        ],
        [
         "1",
         "train_059329.jpg",
         "-1"
        ],
        [
         "2",
         "train_059330.jpg",
         "-1"
        ],
        [
         "3",
         "train_059331.jpg",
         "-1"
        ],
        [
         "4",
         "train_059332.jpg",
         "-1"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Image</td>\n",
       "      <td>Label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_059329.jpg</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_059330.jpg</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_059331.jpg</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_059332.jpg</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Image  Label\n",
       "0             Image  Label\n",
       "1  train_059329.jpg     -1\n",
       "2  train_059330.jpg     -1\n",
       "3  train_059331.jpg     -1\n",
       "4  train_059332.jpg     -1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_unlabelled = pd.read_csv(\"../Dataset/train_unlabeled.csv\", header=None)\n",
    "train_unlabelled.columns = [\"Image\", \"Label\"]\n",
    "train_unlabelled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Dataset/train_unlabeled_0.csv\n",
      "../Dataset/train_unlabeled_1.csv\n",
      "../Dataset/train_unlabeled_2.csv\n",
      "../Dataset/train_unlabeled_3.csv\n",
      "../Dataset/train_unlabeled_4.csv\n",
      "../Dataset/train_unlabeled_5.csv\n"
     ]
    }
   ],
   "source": [
    "n = train_unlabelled.shape[0] // 20_000\n",
    "for i in range(n + 1):\n",
    "    tmp = train_unlabelled.iloc[i * 20_000 : (i + 1) * 20_000]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp.to_csv(f\"../Dataset/train_unlabeled_{i}.csv\", index=False, header=False)\n",
    "    print(f\"../Dataset/train_unlabeled_{i}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Extracting Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from NeuralFeatureExtractor import MobileNetFeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [11:15<00:00, 33.77s/it]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "feature_extractor = MobileNetFeatureExtractor(\n",
    "    result_file=f\"mobilenet_v3_classifier_unlabelled_{i}.npy\"\n",
    ")\n",
    "image_datastore = ImageDatastore(f\"train_unlabeled_{i}\", transform=transform)\n",
    "dataloader = DataLoader(image_datastore, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "features, labels = feature_extractor.compute_features(dataloader)\n",
    "\n",
    "feature_extractor._save_features(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [11:14<00:00, 33.73s/it]\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "feature_extractor = MobileNetFeatureExtractor(\n",
    "    result_file=f\"mobilenet_v3_classifier_unlabelled_{i}.npy\"\n",
    ")\n",
    "image_datastore = ImageDatastore(f\"train_unlabeled_{i}\", transform=transform)\n",
    "dataloader = DataLoader(image_datastore, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "features, labels = feature_extractor.compute_features(dataloader)\n",
    "\n",
    "feature_extractor._save_features(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [11:09<00:00, 33.47s/it]\n"
     ]
    }
   ],
   "source": [
    "i = 2\n",
    "feature_extractor = MobileNetFeatureExtractor(\n",
    "    result_file=f\"mobilenet_v3_classifier_unlabelled_{i}.npy\"\n",
    ")\n",
    "image_datastore = ImageDatastore(f\"train_unlabeled_{i}\", transform=transform)\n",
    "dataloader = DataLoader(image_datastore, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "features, labels = feature_extractor.compute_features(dataloader)\n",
    "\n",
    "feature_extractor._save_features(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [13:08<00:00, 39.42s/it]\n"
     ]
    }
   ],
   "source": [
    "i = 3\n",
    "feature_extractor = MobileNetFeatureExtractor(\n",
    "    result_file=f\"mobilenet_v3_classifier_unlabelled_{i}.npy\"\n",
    ")\n",
    "image_datastore = ImageDatastore(f\"train_unlabeled_{i}\", transform=transform)\n",
    "dataloader = DataLoader(image_datastore, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "features, labels = feature_extractor.compute_features(dataloader)\n",
    "\n",
    "feature_extractor._save_features(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [12:12<00:00, 36.62s/it]\n"
     ]
    }
   ],
   "source": [
    "i = 4\n",
    "feature_extractor = MobileNetFeatureExtractor(\n",
    "    result_file=f\"mobilenet_v3_classifier_unlabelled_{i}.npy\"\n",
    ")\n",
    "image_datastore = ImageDatastore(f\"train_unlabeled_{i}\", transform=transform)\n",
    "dataloader = DataLoader(image_datastore, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "features, labels = feature_extractor.compute_features(dataloader)\n",
    "\n",
    "feature_extractor._save_features(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [08:15<00:00, 35.37s/it]\n"
     ]
    }
   ],
   "source": [
    "i = 5\n",
    "feature_extractor = MobileNetFeatureExtractor(\n",
    "    result_file=f\"mobilenet_v3_classifier_unlabelled_{i}.npy\"\n",
    ")\n",
    "image_datastore = ImageDatastore(f\"train_unlabeled_{i}\", transform=transform)\n",
    "dataloader = DataLoader(image_datastore, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "features, labels = feature_extractor.compute_features(dataloader)\n",
    "\n",
    "feature_extractor._save_features(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_feature_path = '../Features/features/'\n",
    "base_labels_path = '../Features/labels/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "un0 = np.load(os.path.join(base_feature_path, \"mobilenet_v3_classifier_unlabelled_0.npy\"))\n",
    "un1 = np.load(os.path.join(base_feature_path, \"mobilenet_v3_classifier_unlabelled_1.npy\"))\n",
    "un2 = np.load(os.path.join(base_feature_path, \"mobilenet_v3_classifier_unlabelled_2.npy\"))\n",
    "un3 = np.load(os.path.join(base_feature_path, \"mobilenet_v3_classifier_unlabelled_3.npy\"))\n",
    "un4 = np.load(os.path.join(base_feature_path, \"mobilenet_v3_classifier_unlabelled_4.npy\"))\n",
    "un5 = np.load(os.path.join(base_feature_path, \"mobilenet_v3_classifier_unlabelled_5.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels0 = np.load(os.path.join(base_labels_path, \"mobilenet_v3_classifier_unlabelled_0.npy\"))\n",
    "labels1 = np.load(os.path.join(base_labels_path, \"mobilenet_v3_classifier_unlabelled_1.npy\"))\n",
    "labels2 = np.load(os.path.join(base_labels_path, \"mobilenet_v3_classifier_unlabelled_2.npy\"))\n",
    "labels3 = np.load(os.path.join(base_labels_path, \"mobilenet_v3_classifier_unlabelled_3.npy\"))\n",
    "labels4 = np.load(os.path.join(base_labels_path, \"mobilenet_v3_classifier_unlabelled_4.npy\"))\n",
    "labels5 = np.load(os.path.join(base_labels_path, \"mobilenet_v3_classifier_unlabelled_5.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113450, 1280)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "un = np.vstack((un0, un1, un2, un3, un4, un5))\n",
    "un.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(base_feature_path, \"mobilenet_v3_classifier_unlabelled.npy\"), un, allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113450,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.hstack((labels0, labels1, labels2, labels3, labels4, labels5))\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(base_labels_path, \"mobilenet_v3_classifier_unlabelled.npy\"), labels, allow_pickle=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
